# -*- coding: utf-8 -*-
"""Practical Project 1 - Linear Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wiBqSoJVJRbIKyz9bi_mL5U62Z9Yf4Dl

# **Practical Project 1 - Linear Regression**

> Nome: Tiago Miguel Fernandes Marques | Nº: 51653 | Curso: IACD | Aprendizagem Computacional | UBI

Exercício 1
"""

#Importação das Bibliotecas
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import KFold
import matplotlib.pyplot as plt
from sklearn import metrics
from random import uniform
import seaborn as sns
import pandas as pd
import numpy as np
import csv

#Leitura do csv
ficheiro = 'insurance.csv'
df = pd.read_csv(ficheiro)
print(df)

#Caracteriticas das variáveis
print("Carateristicas:")
print(df.info())

"""Exercício 2

**a) Convert all the data to numeric values.**
"""

#Mudança das variáveis categóricas para variáveis numéricas
df['sex'] = df['sex'].map({'female': 0, 'male': 1})
df['smoker'] = df['smoker'].map({'yes': 1, 'no': 0})
df['region_nortesul'] = df['region'].map({'northeast': [1, 1],'northwest': [1, 0],'southeast': [0, 1],'southwest': [0, 0]})

df[['region_norte', 'region_sul']] = pd.DataFrame(df['region_nortesul'].tolist(), index=df.index)

df.drop(columns=['region', 'region_nortesul'], inplace=True)

#Guardar outra vez no csv as mudanças feitas
df.to_csv('insurance.csv', index=False)

print(df)

"""**b)  Check if there are any missing/NULL values**




"""

#Verificar Valores em falta
print("Valores em falta:")
df.isna().sum()

"""**c) Obtain the histogram of each feature, using:**

a. Bar plots
"""

#Mostragem dos gráficos de barra das variáveis em relação ao número de individuos
sns.set(style="darkgrid")

fig, axes = plt.subplots(4, 2, figsize=(12, 10))

sns.histplot(df['age'], bins=8, kde=False, ax=axes[0, 0])
axes[0, 0].set_title('Distribuição da Idade')

sns.countplot(x='sex', data=df, ax=axes[0, 1])
axes[0, 1].set_title('Distribuição de Género')

sns.histplot(df['bmi'], bins=10, kde=False, ax=axes[1, 0])
axes[1, 0].set_title('Distribuição de BMI')

sns.countplot(x='children', data=df, ax=axes[1, 1])
axes[1, 1].set_title('Distribuição de Crianças por Familia')

sns.countplot(x='smoker', data=df, ax=axes[2, 0])
axes[2, 0].set_title('Distribuição dos Fumadores')

sns.countplot(x='region_norte', data=df, ax=axes[2, 1])
axes[2, 1].set_title('Distribuição das Regiões Norte/Sul')

sns.countplot(x='region_sul', data=df, ax=axes[3, 0])
axes[2, 1].set_title('Distribuição das Regiões Sul/Norte')

sns.histplot(df['charges'], bins=10, kde=False, ax=axes[3, 1])
axes[3, 0].set_title('Distribuição dos Custos')

plt.tight_layout()
plt.show()

"""b. Density estimates"""

#Mostragem dos gráficos de densidade das variáveis em relação ao número de individuos
fig, axes = plt.subplots(4, 2, figsize=(12, 10))

sns.kdeplot(x='age', data=df, ax=axes[0,0], fill=True)
axes[0,0].set_title('Distribuição da Idade')

sns.kdeplot(x='sex', data=df, ax=axes[0,1], fill=True)
axes[0,1].set_title('Distribuição de Género')
axes[0,1].set_xticks([0, 1])

sns.kdeplot(x='bmi', data=df, ax=axes[1,0], fill=True)
axes[1,0].set_title('Distribuição de BMI')

sns.kdeplot(x='children', data=df, ax=axes[1,1], fill=True)
axes[1,1].set_title('Distribuição de Crianças por Familia')

sns.kdeplot(x='smoker', data=df, ax=axes[2,0], fill=True)
axes[2,0].set_title('Distribuição dos Fumadores')
axes[2,0].set_xticks([0, 1])

sns.kdeplot(x='region_norte', data=df, ax=axes[2,1], fill=True)
axes[2,1].set_title('Distribuição das Regiões Norte/Sul')
axes[2,1].set_xticks([0, 1])

sns.kdeplot(x='region_sul', data=df, ax=axes[3,0], fill=True)
axes[3,0].set_title('Distribuição das Regiões Sul/Norte')
axes[3,0].set_xticks([0, 1])

sns.kdeplot(x='charges', data=df, ax=axes[3,1], fill=True)
axes[3,1].set_title('Distribuição dos Custos')


plt.tight_layout()
plt.show()

"""**d) Analyze the correlation between features:**

a. Observing the scatter plots between pairs of features.
"""

#Mostragem dos gráficos da relações entre variáveis
sns.pairplot(df)

#Verificar as correlações entre as variáveis
sns.heatmap(df.corr(),annot=True)
plt.show()

"""b. Observing the scatter plots between each feature and the dependent variable."""

#Mostragem dos gráficos da relações entre a variável charges com as outras
sns.pairplot(df, x_vars=['age', 'sex', 'bmi', 'children', 'smoker', 'region_norte','region_sul'], y_vars=['charges'])

#Função para normalzair os dados
def normalizar(coluna):
    minimo = coluna.min()
    maximo = coluna.max()
    coluna_normalizada = []

    for valor in coluna:
        if maximo != minimo:
            valor_normalizado = (valor - minimo) / (maximo - minimo)
        else:
            valor_normalizado = 0
        coluna_normalizada.append(valor_normalizado)

    return coluna_normalizada

for i in df.columns:
    df[i] = normalizar(df[i])

#Guardar outra vez nocsv as mudanças feitas
df.to_csv("insurance.csv", index=False)

"""Exercício 3"""

#Função de custo
def J(X, y, theta):
    preds = np.squeeze(np.matmul(X, theta))
    temp = preds - np.squeeze(y)
    return np.sqrt(np.sum(np.matmul(np.transpose(temp), temp)) / len(y))

#Carregamento do dataset
def ler_csv(file):
    with open(file) as arquivo:
        leitura = csv.reader(arquivo, delimiter=',')
        next(leitura)
        X = []
        y = []

        for row in leitura:
            y.append(float(row[5]))
            X.append([float(row[0]),float(row[1]),float(row[2]),float(row[3]), float(row[4]), float(row[6]),float(row[7]),1])

    X = np.asarray(X)
    y = np.asarray(y)

    return X, y

#Função de descida de gradiente
def descida_gradiente(theta, lr, tol, X, y):
    it = 0
    Js = []
    prev_cost = float('inf')

    while True:
        gradients = np.zeros(theta.shape)


        for j in range(len(y)):
            error = (np.dot(theta, X[j]) - y[j])
            gradients += error * X[j]

        gradients = gradients / len(y)

        theta_old = np.copy(theta)
        theta -= lr * gradients


        current_cost = J(X, y, theta)
        delta = np.sum(np.abs(theta - theta_old))

        print(f'[{it + 1}] J= {current_cost:.5f}, theta = {theta}, delta = {delta}')


        Js.append(current_cost)
        plt.ion()
        plt.figure(1)
        plt.plot(range(len(Js)), Js, '-ko')
        plt.grid(True)
        plt.xlabel('Iterações')
        plt.ylabel('J()')
        plt.show()
        plt.pause(0.1)

        if delta < tol:
            break

        it += 1

    return theta, Js

#Parametros
learning_rate = 0.1
tolerance = 0.001

Features, outs = ler_csv('insurance.csv')

theta_gd = np.asarray([uniform(0., 0.5) for _ in range(Features.shape[1])])

theta_gd, evolution_J = descida_gradiente(theta_gd, learning_rate, tolerance, Features, outs)

train_data_pred = np.matmul(Features, theta_gd)
r2_train = metrics.r2_score(outs, train_data_pred)
print(f"Valor R²: {r2_train}")

"""Exercício 4"""

import numpy as np
import csv
import matplotlib.pyplot as plt
from random import uniform
from sklearn.model_selection import KFold
from sklearn import metrics

# Função de custo
def J(X, y, theta):
    preds = np.squeeze(np.matmul(X, theta))
    temp = preds - np.squeeze(y)
    return np.sqrt(np.sum(np.matmul(np.transpose(temp), temp)) / len(y))

# Carregamento do dataset
def ler_csv(file):
    with open(file) as arquivo:
        leitura_csv = csv.reader(arquivo, delimiter=',')
        next(leitura_csv)
        X = []
        y = []

        for row in leitura_csv:
            y.append(float(row[5]))
            X.append([float(row[0]), float(row[1]), float(row[2]), float(row[3]), float(row[4]), float(row[6]), float(row[7]), 1])

    X = np.asarray(X)
    y = np.asarray(y)

    return X, y

# Função de descida de gradiente
def descida_gradiente(theta, lr, tol, X, y):
    it = 0
    Js = []
    prev_cost = float('inf')

    while True:
        gradients = np.zeros(theta.shape)

        for j in range(len(y)):
            error = (np.dot(theta, X[j]) - y[j])
            gradients += error * X[j]

        gradients = gradients / len(y)

        theta_old = np.copy(theta)
        theta -= lr * gradients

        current_cost = J(X, y, theta)
        delta = np.sum(np.abs(theta - theta_old))

        print(f'[{it + 1}] J= {current_cost:.5f}, theta = {theta}, delta = {delta}')

        Js.append(current_cost)
        plt.ion()
        plt.figure(1)
        plt.plot(range(len(Js)), Js, '-ko')
        plt.grid(True)
        plt.xlabel('Iterações')
        plt.ylabel('J()')
        plt.show()
        plt.pause(0.1)

        if delta < tol:
            break

        it += 1

    return theta, Js

# Função para calcular as métricas de desempenho
def calcular_performance(X, y, theta):
    predictions = np.dot(X, theta)
    rmse = np.sqrt(np.mean((predictions - y) ** 2))
    return rmse

# Função do k-fold
def k_fold(X, y, k, learning_rate, tolerance):
    kf = KFold(n_splits=k)
    performances = []
    final_theta = None

    for train_index, test_index in kf.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        theta_gd = np.asarray([uniform(0., 0.5) for _ in range(X_train.shape[1])])
        theta, _ = descida_gradiente(theta_gd, learning_rate, tolerance, X_train, y_train)

        rmse = calcular_performance(X_test, y_test, theta)
        performances.append(rmse)
        print(f'RMSE por fold: {rmse:.5f}')

        # Armazena o último theta para uso posterior
        final_theta = theta

    mean_rmse = np.mean(performances)
    print(f'Média do RMSE após {k} folds: {mean_rmse:.5f}')
    return final_theta

# Parâmetros
learning_rate = 0.1
tolerance = 0.001
k = 8


Features, outs = ler_csv('insurance.csv')


theta_final = k_fold(Features, outs, k, learning_rate, tolerance)


train_data_pred = np.matmul(Features, theta_final)
r2_train = metrics.r2_score(outs, train_data_pred)
print(f"Valor R²: {r2_train}")

"""Exercício 5"""

# Analyze the differences in performance between the models obtained for the different folds.
# Relatório

"""Exercício 6"""

# Função de custo
def J(X, y, theta):
    preds = np.squeeze(np.matmul(X, theta))
    temp = preds - np.squeeze(y)
    return np.sqrt(np.sum(np.matmul(np.transpose(temp), temp)) / len(y))

# Carregamento do dataset
def ler_csv(file):
    with open(file) as arquivo:
        leitura_csv = csv.reader(arquivo, delimiter=',')
        next(leitura_csv)
        X = []
        y = []

        for row in leitura_csv:
            y.append(float(row[5]))
            X.append([float(row[0]), float(row[1]), float(row[2]), float(row[3]), float(row[4]), float(row[6]), float(row[7])])

    X = np.asarray(X)
    y = np.asarray(y)

    return X, y

# Função para gerar recursos polinomiais
def polinomios(X, p):
    poly = PolynomialFeatures(degree=p, include_bias=False)
    return poly.fit_transform(X)

# Função de descida de gradiente
def descida_gradiente(theta, lr, tol, X, y):
    it = 0
    Js = []
    while True:
        gradients = np.zeros(theta.shape)

        for j in range(len(y)):
            error = (np.dot(theta, X[j]) - y[j])
            gradients += error * X[j]

        gradients = gradients / len(y)
        theta_old = np.copy(theta)
        theta -= lr * gradients

        current_cost = J(X, y, theta)

        delta = np.sum(np.abs(theta - theta_old))

        print(f'[{it + 1}] J= {current_cost:.5f}, theta = {theta}, delta = {delta}')

        Js.append(current_cost)
        plt.ion()
        plt.figure(1)
        plt.plot(range(len(Js)), Js, '-ko')
        plt.grid(True)
        plt.xlabel('Iterações')
        plt.ylabel('J()')
        plt.show()
        plt.pause(0.1)

        if delta < tol:
            break

        it += 1

    return theta, Js

# Função para calcular as métricas de desempenho
def calcular_performance(X, y, theta):
    predictions = np.dot(X, theta)
    rmse = np.sqrt(np.mean((predictions - y) ** 2))
    return rmse

# Função de validação cruzada K-Fold
def k_fold(X, y, k, learning_rate, tolerance, p):
    kf = KFold(n_splits=k)
    performances = []

    for train_index, test_index in kf.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]


        X_train_poly = polinomios(X_train, p)
        X_test_poly = polinomios(X_test, p)


        theta_gd = np.asarray([uniform(0., 0.5) for _ in range(X_train_poly.shape[1])])


        theta, _ = descida_gradiente(theta_gd, learning_rate, tolerance, X_train_poly, y_train)


        rmse = calcular_performance(X_test_poly, y_test, theta)
        performances.append(rmse)
        print(f'RMSE por fold: {rmse:.5f}')

    mean_rmse = np.mean(performances)
    print(f'Média do RMSE após {k} folds: {mean_rmse:.5f}')

# Parâmetros
p = 1
learning_rate = 0.1
tolerance = 0.001
k = 3


Features, outs = ler_csv('insurance.csv')

k_fold(Features, outs, k, learning_rate, tolerance, p)